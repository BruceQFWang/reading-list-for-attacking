# Reading list for attacking

**[1]**   Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey. 英文综述 [link](https://arxiv.org/pdf/1801.00553.pdf)   

**[2]**   知乎专栏，前几章有介绍样本对抗攻防的基础的 [link](https://zhuanlan.zhihu.com/c_170476465) 

**[3]**   pytorch官方文档----60分钟入门  [link](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) 

**[4]**   样本对抗的来龙去脉和本质  [link](http://baijiahao.baidu.com/s?id=1596201339578975526&wfr=spider&for=pc) 

**[5]**   样本对抗的一个相关比赛  [link](https://tianchi.aliyun.com/competition/entrance/231701/introduction?spm=5176.12281957.1004.2.38b04c2aac5bGR) 

**[6]**   Awesome ML Attack  [link](https://github.com/yenchenlin/awesome-adversarial-machine-learning) 

**[7]**   简单易懂的人脸识别过程和原理介绍 [link](https://blog.csdn.net/LEON1741/article/details/81358974) 

**[8]**   一种鲁棒的神经网络架构(防御) [link](https://arxiv.org/abs/1802.07896)

**[9]**   对抗训练论文一(防御) [link](https://arxiv.org/abs/1805.04807)


# Open Source about ADVERSARIAL EXAMPLE GENERATION

**[1]** PyTorch FGSM Tutorial [link](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html)

**[2]** PyTorch C&W Attack [link](https://github.com/rwightman/pytorch-nips2017-attack-example)

**[3]** PyTorch DNN Attack(CVPR2019) [link](https://github.com/jeromerony/fast_adversarial)

# Face Recognition

**[1]** Loss Function for training Face Recognition Model [link](https://zhuanlan.zhihu.com/p/34404607)

**[2]** Face Recognition Model: ZhaoJ9014/face.evoLVe.PyTorch （默认白盒模型） [link](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch)

**[3]** Face Recognition Model: ageitgey/face_recognition （第一次老师给的白盒模型） [link](https://github.com/ageitgey/face_recognition)



# Neural network backdoor
**[1]** Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks. [link](http://people.cs.uchicago.edu/~ravenben/publications/pdf/backdoor-sp19.pdf)   翻译 [link](https://blog.csdn.net/qq_38232598/article/details/89244310)

**[2]** Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning. [link](https://arxiv.org/pdf/1712.05526.pdf)

**[3]** A General Framework for Adversarial Examples with Objectives. [link](https://arxiv.org/pdf/1801.00349.pdf)  机器之心的解读[link](https://www.jiqizhixin.com/articles/2018-01-08-5)

